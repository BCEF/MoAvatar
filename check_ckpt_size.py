import torch
import sys

def calculate_dict_size(obj, visited=None):
    """é€’å½’è®¡ç®—å­—å…¸æˆ–å…¶ä»–å¯¹è±¡çš„å®é™…å†…å­˜å¤§å°"""
    if visited is None:
        visited = set()
    
    # é¿å…å¾ªç¯å¼•ç”¨
    obj_id = id(obj)
    if obj_id in visited:
        return 0
    visited.add(obj_id)
    
    total_size = 0
    
    if isinstance(obj, torch.Tensor):
        return obj.numel() * obj.element_size()
    elif hasattr(obj, 'nbytes'):  # numpyæ•°ç»„
        return obj.nbytes
    elif isinstance(obj, dict):
        total_size += sys.getsizeof(obj)  # å­—å…¸æœ¬èº«çš„å¤§å°
        for key, value in obj.items():
            total_size += sys.getsizeof(key)  # é”®çš„å¤§å°
            total_size += calculate_dict_size(value, visited)  # é€’å½’è®¡ç®—å€¼çš„å¤§å°
    elif isinstance(obj, (list, tuple)):
        total_size += sys.getsizeof(obj)
        for item in obj:
            total_size += calculate_dict_size(item, visited)
    elif isinstance(obj, str):
        total_size += sys.getsizeof(obj)
    else:
        # å¯¹äºè‡ªå®šä¹‰å¯¹è±¡ï¼Œæ£€æŸ¥å…¶æ‰€æœ‰å±æ€§
        total_size += sys.getsizeof(obj)
        
        # å°è¯•è·å–å¯¹è±¡çš„æ‰€æœ‰å±æ€§
        try:
            if hasattr(obj, '__dict__'):
                for attr_name, attr_value in obj.__dict__.items():
                    total_size += sys.getsizeof(attr_name)  # å±æ€§åå¤§å°
                    total_size += calculate_dict_size(attr_value, visited)  # å±æ€§å€¼å¤§å°
            elif hasattr(obj, '__slots__'):
                for slot in obj.__slots__:
                    if hasattr(obj, slot):
                        attr_value = getattr(obj, slot)
                        total_size += sys.getsizeof(slot)  # æ§½åå¤§å°
                        total_size += calculate_dict_size(attr_value, visited)  # æ§½å€¼å¤§å°
        except (AttributeError, RecursionError):
            # å¦‚æœæ— æ³•è®¿é—®å±æ€§ï¼Œåªè¿”å›å¯¹è±¡æœ¬èº«çš„å¤§å°
            pass
    
    return total_size

def analyze_deformation_graph(dg_obj):
    """åˆ†æDeformationGraphå¯¹è±¡çš„è¯¦ç»†ä¿¡æ¯"""
    print(f"\nğŸ”— DeformationGraph è¯¦ç»†åˆ†æ:")
    print(f"  - å¯¹è±¡ç±»å‹: {type(dg_obj).__module__}.{type(dg_obj).__name__}")
    
    total_size_mb = 0
    
    if hasattr(dg_obj, '__dict__'):
        print(f"  - å±æ€§åˆ—è¡¨:")
        for attr_name, attr_value in dg_obj.__dict__.items():
            attr_type = type(attr_value).__name__
            attr_size_mb = 0
            
            if isinstance(attr_value, torch.Tensor):
                attr_size_mb = attr_value.numel() * attr_value.element_size() / (1024**2)
                print(f"    * {attr_name}: Tensor{list(attr_value.shape)} ({attr_size_mb:.2f} MB)")
                
            elif hasattr(attr_value, 'nbytes'):  # numpyæ•°ç»„
                attr_size_mb = attr_value.nbytes / (1024**2)
                print(f"    * {attr_name}: {attr_type}{list(attr_value.shape)} ({attr_size_mb:.2f} MB)")
                
            elif isinstance(attr_value, (list, tuple)) and len(attr_value) > 0:
                # è®¡ç®—åˆ—è¡¨çš„å®é™…å¤§å°
                list_size_bytes = calculate_dict_size(attr_value)
                attr_size_mb = list_size_bytes / (1024**2)
                
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹ä»¥è·å–æ›´å¤šä¿¡æ¯
                first_elem_type = type(attr_value[0]).__name__ if len(attr_value) > 0 else "empty"
                print(f"    * {attr_name}: {attr_type}[{len(attr_value)} {first_elem_type}] ({attr_size_mb:.2f} MB)")
                
                # å¦‚æœæ˜¯å°åˆ—è¡¨ï¼Œæ˜¾ç¤ºä¸€äº›æ ·æœ¬
                if len(attr_value) <= 5:
                    for i, item in enumerate(attr_value):
                        item_type = type(item).__name__
                        if hasattr(item, 'shape'):
                            print(f"      [{i}]: {item_type}{list(item.shape)}")
                        elif hasattr(item, '__len__') and not isinstance(item, str):
                            print(f"      [{i}]: {item_type}[{len(item)}]")
                        else:
                            print(f"      [{i}]: {item_type}")
                            
            elif isinstance(attr_value, dict):
                dict_size_bytes = calculate_dict_size(attr_value)
                attr_size_mb = dict_size_bytes / (1024**2)
                print(f"    * {attr_name}: {attr_type}[{len(attr_value)} items] ({attr_size_mb:.2f} MB)")
                    
            else:
                # å…¶ä»–ç±»å‹ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•è®¡ç®—å¤§å°
                obj_size_bytes = calculate_dict_size(attr_value)
                attr_size_mb = obj_size_bytes / (1024**2)
                
                size_info = ""
                if hasattr(attr_value, '__len__'):
                    try:
                        size_info = f"[{len(attr_value)}]"
                    except:
                        pass
                        
                if attr_size_mb >= 0.01:  # åªæ˜¾ç¤ºå¤§äº0.01MBçš„
                    print(f"    * {attr_name}: {attr_type}{size_info} ({attr_size_mb:.2f} MB)")
                else:
                    print(f"    * {attr_name}: {attr_type}{size_info} ({attr_value})")
            
            total_size_mb += attr_size_mb
    
    print(f"  - æ€»å¤§å°: {total_size_mb:.2f} MB")
    
    return total_size_mb

def quick_ckpt_info(ckpt_path):
    """
    å¿«é€ŸæŸ¥çœ‹checkpointåŸºæœ¬ä¿¡æ¯
    """
    print(f"ğŸ” å¿«é€Ÿåˆ†æ: {ckpt_path}")
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(ckpt_path, weights_only=False, map_location='cpu')
    
    # å¦‚æœæ˜¯å…ƒç»„ï¼Œè§£åŒ…
    if isinstance(checkpoint, tuple):
        (
            features_dc,          # ä¿®å¤å˜é‡å
            features_rest,        # ä¿®å¤å˜é‡å  
            opacity,              # ä¿®å¤å˜é‡å
            xyz_0,                # ä¿®å¤å˜é‡å
            rotation_0,           # ä¿®å¤å˜é‡å
            scaling_0,            # ä¿®å¤å˜é‡å
            xyz_mlp_state_dict,
            rot_mlp_state_dict,
            scale_mlp_state_dict,
            dg,
            base_xyz,
            # temp_flame_vertices
        ) = checkpoint
        
        ckpt_list = {

            "features_dc": features_dc,
            "features_rest": features_rest,
            "opacity": opacity,
            "xyz_0": xyz_0,
            "rotation_0": rotation_0,
            "scaling_0": scaling_0,
            "xyz_mlp_state_dict": xyz_mlp_state_dict,
            "rot_mlp_state_dict": rot_mlp_state_dict,
            "scale_mlp_state_dict": scale_mlp_state_dict,
            "dg": dg,
            "base_xyz": base_xyz,
        }
    else:
        # å¦‚æœæ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
        ckpt_list = checkpoint
    
    total_params = 0
    total_size_bytes = 0
    
    print(f"{'='*60}")
    print(f"{'é”®å':<25} {'å¤§å°(MB)':<15} {'å‚æ•°æ•°é‡':<15} {'ç±»å‹'}")
    print(f"{'='*60}")
    
    for key, value in ckpt_list.items():
        if isinstance(value, torch.Tensor):
            size_bytes = value.numel() * value.element_size()
            size_mb = size_bytes / (1024**2)
            total_params += value.numel()
            total_size_bytes += size_bytes
            print(f"{key:<25} {size_mb:<15.2f} {value.numel():<15,} Tensor{list(value.shape)}")
            
        elif isinstance(value, dict):
            # æ£€æŸ¥å­—å…¸ä¸­æ˜¯å¦åŒ…å«tensor
            tensor_size = 0
            tensor_params = 0
            dict_total_size = 0
            
            for sub_key, sub_value in value.items():
                if isinstance(sub_value, torch.Tensor):
                    sub_size = sub_value.numel() * sub_value.element_size()
                    tensor_size += sub_size
                    tensor_params += sub_value.numel()
            
            # è®¡ç®—æ•´ä¸ªå­—å…¸çš„å®é™…å¤§å°
            dict_total_size = calculate_dict_size(value)
            
            size_mb = dict_total_size / (1024**2)
            total_params += tensor_params
            total_size_bytes += dict_total_size
            
            tensor_count = sum(1 for v in value.values() if isinstance(v, torch.Tensor))
            print(f"{key:<25} {size_mb:<15.2f} {tensor_params:<15,} Dict({tensor_count} tensors)")
            
        else:
            # å…¶ä»–ç±»å‹çš„æ•°æ®
            obj_size = calculate_dict_size(value)
            size_mb = obj_size / (1024**2)
            total_size_bytes += obj_size
            
            # ç‰¹æ®Šå¤„ç†DeformationGraphå¯¹è±¡
            if hasattr(value, '__class__') and 'DeformationGraph' in value.__class__.__name__:
                dg_tensor_size = analyze_deformation_graph(value)
                # æ›´æ–°æ˜¾ç¤ºçš„å¤§å°ä¸ºå®é™…tensorå¤§å°
                print(f"{key:<25} {dg_tensor_size:<15.2f} {0:<15} {type(value).__name__}")
            else:
                print(f"{key:<25} {size_mb:<15.2f} {0:<15} {type(value).__name__}")
                if size_mb < 0.01:  # å¦‚æœå¾ˆå°ï¼Œæ˜¾ç¤ºå…·ä½“å€¼
                    print(f"  â””â”€ å€¼: {value}")
    
    print(f"{'='*60}")
    print(f"\nğŸ“Š æ€»ç»“:")
    print(f" - æ€»å‚æ•°é‡: {total_params:,}")
    print(f" - æ€»å¤§å°: {total_size_bytes / (1024**2):.2f} MB ({total_size_bytes / (1024**3):.2f} GB)")
    print(f" - æ–‡ä»¶è·¯å¾„: {ckpt_path}")

if __name__ == "__main__":  # ä¿®å¤è¯­æ³•é”™è¯¯
    # ç¤ºä¾‹ç”¨æ³•
    path = "/home/momo/Desktop/data/ali/cc01data/output/02_frames_test/chkpnt142000_render.pth"
    quick_ckpt_info(path)